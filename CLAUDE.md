# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

LMRC Digital Noticeboard is a self-updating digital signage application for Lake Macquarie Rowing Club. It displays rotating content from the club's RevSport website including photo galleries, events, news, and sponsors on a TV in the boatshed.

**Tech Stack**: Node.js + Express backend, React 18 frontend, Puppeteer for web scraping, Vite for building

## Architecture

The application has a **3-layer architecture** running on a single device (Raspberry Pi/NUC):

1. **Scraper Layer** (`scraper/noticeboard-scraper.js`)
   - Puppeteer-based headless browser
   - Authenticates with RevSport using credentials from `.env`
   - Scrapes gallery albums, events, news articles, and sponsors
   - Saves data to local JSON files in `data/` directory
   - Runs hourly via cron job (production) or manually via `npm run scrape`

2. **API Server Layer** (`server.js`)
   - Express server serving both the built React app and API endpoints
   - Endpoints: `/api/gallery`, `/api/events`, `/api/news`, `/api/config`, `/api/health`
   - Reads JSON files from `data/` directory and serves them
   - Includes file age tracking to detect stale data
   - Managed by PM2 in production

3. **Frontend Layer** (`src/Noticeboard.jsx`)
   - Single-file React application (intentionally monolithic for simplicity)
   - Three-panel layout: Events (left), Hero/Gallery (center), News (right)
   - Polls API endpoints every 60 seconds for updates
   - Automatic content rotation based on `config.json` timing settings
   - Runs in Chromium kiosk mode (fullscreen) in production

**Data Flow**: RevSport → Puppeteer Scraper → JSON files → Express API → React Frontend → Chromium Display

**Why this architecture?**
- Avoids CORS issues (server-side scraping, same-origin API)
- No authentication required (RevSport site is publicly accessible)
- Offline-capable (displays last known data if scraper fails)
- Single-device deployment (no external dependencies except RevSport)

## Common Commands

### Development
```bash
npm run dev              # Start both dev:server and dev:react concurrently
npm run dev:server       # Server on port 3000 (nodemon auto-restart)
npm run dev:react        # Vite dev server on port 5173 (with HMR)
npm run build            # Build React app to public/ directory
```

### Production
```bash
npm start                # Start Express server (serves built app from public/)
npm run scrape           # Manually run scraper once
```

### Testing
```bash
npm test                 # Run test-scraper.js (scraper validation)
curl http://localhost:3000/api/health    # Check server health
curl http://localhost:3000/api/gallery   # Test gallery endpoint
```

## Key File Locations

- **Configuration**: `config.json` (all display settings, timing, branding)
- **Scraped Data**: `data/*.json` (gallery-data, events-data, news-data, sponsors-data)
- **Built App**: `public/` (generated by Vite, git-ignored)
- **Entry Point**: `index.html` (Vite entry, imports src/Noticeboard.jsx)

## Configuration System

`config.json` is the single source of truth for all display settings:

- **`timing`**: Rotation intervals for all content (heroRotationSeconds, newsPanelRotationSeconds, etc.)
- **`branding`**: Club name, logo paths, colors, tagline
- **`gallery`/`events`/`news`**: Max items to display, filtering options
- **`weather`**: Location coordinates for weather data
- **`sponsors`**: Array of sponsor objects with logo paths
- **`display`**: Layout percentages and resolution
- **`socialMedia`**: Facebook and Instagram settings
- **`advanced`**: Animations, transitions, effects, logging

**Important**: Config changes are detected automatically within 60 seconds (no server restart needed).

### Web-Based Configuration Editor

A web interface is available for managing configuration settings without manually editing JSON:

**Access**: Navigate to `http://localhost:3000/config` (or your server's IP:3000/config)

**Features**:
- Organized sections for all configuration options
- Color pickers for branding colors
- Input validation to prevent invalid configurations
- Automatic backup creation before saving changes
- Reset to backup functionality
- Unsaved changes warning
- Real-time form validation

**Usage**:
1. Navigate to `/config` in your browser
2. Modify any settings using the form controls
3. Click "Save Changes" to apply (creates automatic backup)
4. Changes take effect within 60 seconds on the noticeboard
5. Use "Reset to Backup" to undo changes if needed

**API Endpoints**:
- `GET /api/config/full` - Retrieve complete configuration
- `POST /api/config/update` - Update configuration (validates required sections)
- `POST /api/config/reset` - Restore from backup (config.json.backup)

## Scraper Details

The scraper (`scraper/noticeboard-scraper.js`) uses Puppeteer to scrape public pages:

1. `/gallery` → album list → individual album pages for photos
2. `/events/list` → upcoming events
3. `/news` → announcements and results
4. `/home` → sponsor information

**No authentication required** - all RevSport public pages are accessible without login.

### Portability for Other RevSport Clubs

**The noticeboard is fully portable to other RevSport club websites!**

All scraper URLs are **configurable** via `config.json`:

```json
"scraper": {
  "baseUrl": "https://www.lakemacquarierowingclub.org.au",
  "paths": {
    "gallery": "/gallery",
    "events": "/events/list",
    "news": "/news",
    "sponsors": "/home"
  },
  "maxRetries": 3,
  "timeoutSeconds": 30
}
```

**For other clubs:**
- Change `baseUrl` to your club's RevSport website
- Adjust `paths` if your instance uses different URL structures
  - Example: Jindabyne Rowing Club uses `https://www.revolutionise.com.au/jindyrowers`
- Update branding, colors, and timing in `config.json`
- No credentials needed!

**Output Format**: Each scraper method writes to `data/{type}-data.json` with structure:
```javascript
{
  scrapedAt: "2025-10-20T10:30:00.000Z",
  dataType: "gallery|events|news|sponsors",
  itemCount: 10,
  items: [...]  // Array of scraped items
}
```

**Retry Logic**: Configurable via `config.scraper.maxRetries` and `config.scraper.timeoutSeconds`

**Important Selectors**:
- Gallery albums: `a[href*="/gallery/"]`
- Album photos: `img[data-gallery-image]` or `.gallery-item img`
- Events: `.event-item` or table rows
- News: `.news-article` or similar

## Frontend Structure

`src/Noticeboard.jsx` is a **single-file React component** (intentional design for simplicity):

**State Management**:
- Config, gallery, events, news, sponsors, weather (from API)
- Rotation indices: heroIndex, currentNewsIndex, sponsorGroupIndex
- Current time for clock display

**Effects**:
- Config polling (60s)
- Data polling (configurable, default 60s)
- Hero rotation timer (default 15s)
- News rotation timer (default 45s)
- Sponsor rotation timer (default 30s)
- Weather refresh (default 30min)
- Clock update (1s)

**Layout**: Three-column CSS Grid (25% | 50% | 25%) with sticky events panel

**Styling**: Inline styles using config.branding.clubColors

## Environment Variables

Optional in `.env`:
```bash
PORT=3000                    # Optional, defaults to 3000
NODE_ENV=production          # Optional, for production optimization
```

**No credentials required** - the scraper accesses only public pages.

## Deployment Specifics

**Production Environment**: Raspberry Pi 5 (8GB) or Intel NUC

**Process Management**: PM2
```bash
pm2 start server.js --name lmrc-noticeboard
pm2 startup
pm2 save
```

**Automated Scraping**: Crontab entry
```cron
5 * * * * cd /home/pi/lmrc-noticeboard && node scraper/noticeboard-scraper.js >> scraper.log 2>&1
```

**Kiosk Mode**: Chromium auto-starts fullscreen on boot (see DEPLOYMENT.md for autostart config)

## Development Workflow

1. **Making config changes**: Edit `config.json` → changes apply within 60s (no restart)
2. **Making frontend changes**: Edit `src/Noticeboard.jsx` → `npm run build` → refresh browser
3. **Making server changes**: Edit `server.js` → server auto-restarts (nodemon in dev)
4. **Making scraper changes**: Edit `scraper/noticeboard-scraper.js` → `npm run scrape` to test
5. **Testing scraper**: `npm test` or `npm run scrape` and check `data/*.json`

## Common Issues

**No data showing**: Run `npm run scrape` to populate `data/` directory, check `ls -lh data/`
**Stale data warning**: Scraper may have failed, check cron logs or run manually
**Port 3000 in use**: Change PORT in `.env` or kill existing process on port 3000
**Scraper fails**: Verify RevSport site is accessible and URLs in `config.json` are correct

## Code Patterns

**Adding a new API endpoint**:
```javascript
app.get('/api/newdata', async (req, res) => {
  const filepath = path.join(DATA_DIR, 'newdata.json');
  const data = await readJSONFile(filepath);
  if (!data) return res.status(404).json({ error: 'Not available' });
  res.json(data);
});
```

**Adding a new scraper method**:
```javascript
async scrapeNewContent() {
  await this.page.goto(`${BASE_URL}/newpage`);
  await this.page.waitForSelector('.selector');
  const data = await this.page.evaluate(() => { /* extraction logic */ });
  await this.saveData('newdata.json', { items: data });
}
```

**Adding a new config section**: Edit `config.json`, then access in React via `config.newSection`

## Browser Compatibility

Built for **Chromium 120+** (Raspberry Pi OS default). Uses modern React 18 features but transpiled to ES2015 via Vite for broader compatibility.

## Security Notes

- `.gitignore` includes `.env`, `data/`, `node_modules/`, `public/`
- API endpoints are read-only (no POST/PUT/DELETE except for config management)
- Scraper accesses only public pages (no credentials needed)
- Configuration API (`/api/config/update`) validates input to prevent malformed config
